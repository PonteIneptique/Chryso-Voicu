{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7162a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from freestyl.dataset.dataframe_wrapper import DataframeWrapper\n",
    "from freestyl.supervised.siamese import train_dataframewrappers, get_df_prediction\n",
    "from freestyl.supervised.siamese.utils import score_from_preds, find_index_of_first_change\n",
    "from freestyl.utils import plot_aucroc_curve\n",
    "#>>> x = [1, 2, 3, 4, 5, 6]\n",
    "#>>> .shuffle(x)\n",
    "\n",
    "NEW_DATASET = False\n",
    "SPLIT_ON_AUTHORS = False\n",
    "USE_POS = True\n",
    "USE_TRIG = True\n",
    "USE_FW = True\n",
    "LR = 1e-4\n",
    "BATCH = 64\n",
    "DROPOUT = .3\n",
    "LOSS = \"stn_contrastive\"\n",
    "CHRYSOSTOM = False\n",
    "SAMPLE = 2\n",
    "DYDIMUS = True\n",
    "COMMENT = False\n",
    "DEV_MINER = True\n",
    "SPLIT = False\n",
    "ISDIST = \"linear\" not in LOSS\n",
    "METRICKEY = \"Probability\" if not ISDIST else \"Distance\"\n",
    "\n",
    "if SPLIT:\n",
    "    SIZE = (32, 32, 32)\n",
    "elif USE_POS and not USE_FW:\n",
    "    SIZE = 50\n",
    "elif USE_POS and USE_FW:\n",
    "    SIZE = 64\n",
    "else:\n",
    "    SIZE = 64\n",
    "    \n",
    "seed = 42\n",
    "IGNORE_KEYS = [\n",
    "    \"file\", \"author\", \"textgroup\", \"title\", \"tokens\", \"length\", \"modified_text\"\n",
    "]\n",
    "REMOVED = [\"Euclides\"]\n",
    "\n",
    "\n",
    "def make_file_name(filename: str) -> str:\n",
    "    *x, y = filename.split(\".\")\n",
    "    x = \".\".join(x)\n",
    "    *dirs, x = x.split(\"/\")\n",
    "    dirs = \"/\".join(dirs)\n",
    "    print()\n",
    "    name = f\"TRI[{USE_TRIG}]B[{BATCH}]Do[{DROPOUT}]Min[{DEV_MINER}]Split[{SPLIT}]Pos[{USE_POS}]FW[{USE_FW}]LR[{LR}]SIZE[{SIZE}]LOSS[{LOSS}]CHRYS[{CHRYSOSTOM}]DYD[{DYDIMUS}]SAMPLE[{SAMPLE}]COMMENT[{COMMENT}].{x}.{y}\"\n",
    "    if dirs:\n",
    "        return f\"{dirs}/{name}\"\n",
    "    return name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce50a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97a05a14",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48da1ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dev_test(filtre, seed=42, ratio=10):\n",
    "    test = len(filtre) * ratio // 100\n",
    "    dev_and_test = test * 2\n",
    "    print(f\"Train categorical samples: {len(filtre)-dev_and_test}\")\n",
    "    print(f\"Dev   categorical samples: {dev_and_test-test}\")\n",
    "    print(f\"Test  categorical samples: {test}\")\n",
    "    r = random.Random(seed)\n",
    "    r.shuffle(filtre)\n",
    "    return filtre[:-dev_and_test], filtre[-dev_and_test:-test], filtre[-test:]\n",
    "\n",
    "\n",
    "if NEW_DATASET:\n",
    "    df = pd.read_csv(\"tlg-features.csv\").sample(frac=1)\n",
    "    #df = df[df.tokens >= 5000]\n",
    "    #print(\">= 5000\", df.shape)\n",
    "    #df = df[~df.file.isin(POETRY)]\n",
    "    #print(\">= Poetry\", df.shape)\n",
    "    # df = df[~df.title.str.contains(\"Dub\\.|Sp\\.|Fragm|Excerpt|(e cod\\.)|Suda|recensio|fragm|sp\\.|dub\\.|(fort\\. auctore)|Scholia\")]\n",
    "    print(\"Title filter\", df.shape)\n",
    "    #df = df[~df[\"full-pos-text\"].isna()]\n",
    "    #print(\">= POS missing\", df.shape)\n",
    "    \n",
    "    # Filter based on authors, to generalize better. Everything should be out of domain\\\n",
    "    train, dev, test = [], [], []\n",
    "    if SPLIT_ON_AUTHORS:\n",
    "        authors = df.author.value_counts()\n",
    "        a, b, c = get_train_dev_test(authors[authors > 1].index.tolist())\n",
    "    else:\n",
    "        a, b, c = get_train_dev_test(df.title.unique().tolist())\n",
    "        \n",
    "    train.extend(a)\n",
    "    dev.extend(b)\n",
    "    test.extend(c)\n",
    "    \n",
    "#     a, b, c = get_train_dev_test(authors[authors == 1].index.tolist())\n",
    "#     train.extend(a)\n",
    "#     dev.extend(b)\n",
    "#     test.extend(c)\n",
    "\n",
    "    if SPLIT_ON_AUTHORS:\n",
    "        train = df[df.author.isin(train)].copy(deep=True)\n",
    "        dev = df[df.author.isin(dev)].copy(deep=True)#.author.value_counts()\n",
    "        test = df[df.author.isin(test)].copy(deep=True)#.author.value_counts()\n",
    "    else:\n",
    "        train = df[df.title.isin(train)].copy(deep=True)\n",
    "        dev = df[df.title.isin(dev)].copy(deep=True)#.author.value_counts()\n",
    "        test = df[df.title.isin(test)].copy(deep=True)#.author.value_counts()\n",
    "        \n",
    "    train.to_csv(\"tlg-train.csv\", index=False)\n",
    "    dev.to_csv(\"tlg-dev.csv\", index=False)\n",
    "    test.to_csv(\"tlg-test.csv\", index=False)\n",
    "else:\n",
    "    train = pd.read_csv(\"tlg-train.csv\")\n",
    "    dev = pd.read_csv(\"tlg-dev.csv\")\n",
    "    test = pd.read_csv(\"tlg-test.csv\")\n",
    "    \n",
    "train = train[~train.author.isin(REMOVED)]\n",
    "dev = dev[~dev.author.isin(REMOVED)]\n",
    "test = test[~test.author.isin(REMOVED)]\n",
    "\n",
    "if not CHRYSOSTOM:\n",
    "    train = train[~train.author.str.contains(\"Chrysosto\")]\n",
    "    dev = dev[~dev.author.str.contains(\"Chrysosto\")]\n",
    "    test = test[~test.author.str.contains(\"Chrysosto\")]\n",
    "    \n",
    "if not DYDIMUS:\n",
    "    train = train[~train.author.str.contains(\"Didym\")]\n",
    "    dev = dev[~dev.author.str.contains(\"Didym\")]\n",
    "    test = test[~test.author.str.contains(\"Didym\")]\n",
    "    \n",
    "if not COMMENT:\n",
    "    train = train[~train.title.str.contains(\"Comment\")]\n",
    "    dev = dev[~dev.title.str.contains(\"Comment\")]\n",
    "    test = test[~test.title.str.contains(\"Comment\")]\n",
    "\n",
    "print(f\"Train Shape : {train.shape}\")\n",
    "print(f\"Dev Shape : {dev.shape}\")\n",
    "print(f\"Test Shape : {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ed12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.title.str.contains(\"Comment\").value_counts()\n",
    "test.title.str.contains(\"Comment\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a21e87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.title.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66716c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, dpi=300, figsize = (23, 4), sharey=True)\n",
    "train.author.value_counts().plot.bar(ax=ax1)\n",
    "dev.author.value_counts().plot.bar(ax=ax2)\n",
    "test.author.value_counts().plot.bar(ax=ax3)\n",
    "fig.savefig(make_file_name(\"samples.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f1fe97",
   "metadata": {},
   "source": [
    "## Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93104837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_normalization(dfw):\n",
    "    dfw.normalized._dataframe = dfw.dataframe.fillna(0)\n",
    "    \n",
    "def get_scores(scores, distance: float, col=METRICKEY, noprint=False) -> None:\n",
    "\n",
    "    if \"distance\" in col.lower():\n",
    "        scores[\"Attribution\"] = scores[col] <= distance\n",
    "    else:\n",
    "        scores[\"Attribution\"] = scores[col] >= distance\n",
    "    \n",
    "    pos = scores[scores.IsAPair].Attribution.value_counts().to_dict()\n",
    "    negs = scores[~scores.IsAPair].Attribution.value_counts().to_dict()\n",
    "    \n",
    "    tp = pos.get(True, 0)\n",
    "    fn = pos.get(False, 0)\n",
    "    fp = negs.get(True, 0)\n",
    "    tn = negs.get(False, 0)\n",
    "    \n",
    "    if noprint is False:\n",
    "        print(f\"True positives: {tp}\\nFalse Negative {fn}\")\n",
    "        print(f\"True Negative {tn}\")\n",
    "        print(f\"False positives: {fp}\\nAccuracy: {tp/(fn+tp):.2f}\")\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c933d1b0",
   "metadata": {},
   "source": [
    "## Automatically retrieve some constant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03479c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_COLS = [\n",
    "    col\n",
    "    for col in train.columns\n",
    "    if col.startswith(\"$POS$\")\n",
    "]\n",
    "FW_COLS = [\n",
    "    col\n",
    "    for col in train.columns\n",
    "    if col.startswith(\"$MFW$\")\n",
    "]\n",
    "TRIG_COLS = [\n",
    "    col\n",
    "    for col in train.columns\n",
    "    if col.startswith(\"$TRI$\")\n",
    "]\n",
    "KEEP = [] + (\n",
    "    POS_COLS if USE_POS else []\n",
    ") + (\n",
    "    FW_COLS if USE_FW else []\n",
    ") + (\n",
    "    TRIG_COLS if USE_TRIG else []\n",
    ")\n",
    "IGNORE = [\n",
    "    col for col in train.columns\n",
    "    if col not in KEEP\n",
    "]\n",
    "\n",
    "print(IGNORE_KEYS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d218e4",
   "metadata": {},
   "source": [
    "## Get DataFrameWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa538a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataframeWrapper(train, target=\"author\", label=[\"author\", \"title\"], x_ignore=IGNORE)\n",
    "assign_normalization(data)\n",
    "data_dev = DataframeWrapper(dev, target=\"author\", label=[\"author\", \"title\"], x_ignore=IGNORE)\n",
    "data_dev.update_features(data.features)\n",
    "assign_normalization(data_dev)\n",
    "data_test = DataframeWrapper(test, target=\"author\", label=[\"author\", \"title\"], x_ignore=IGNORE)\n",
    "data_test.update_features(data.features)\n",
    "assign_normalization(data_test)\n",
    "data._x_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f31594",
   "metadata": {},
   "source": [
    "## CHecking some details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d3f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.normalized.xs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307d8cf",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e62a60c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models, train_trainer = train_dataframewrappers(\n",
    "    train=data,\n",
    "    dev=data_dev,\n",
    "    test=data_test,\n",
    "    optim=\"Adam\",\n",
    "    accelerator=\"gpu\",\n",
    "    # 2e-5, Batch 32\n",
    "    learning_rate=LR,\n",
    "    margin=1,\n",
    "    dimension=SIZE,\n",
    "    loss=LOSS,\n",
    "    pos_strategy=\"easy\",\n",
    "    neg_strategy=\"semihard\",\n",
    "    sample=SAMPLE,\n",
    "    batch_size=BATCH,\n",
    "    gpus=1,\n",
    "    dropout=DROPOUT,\n",
    "    min_epochs=100,\n",
    "    miner_for_dev=DEV_MINER,\n",
    "    split_dim=find_index_of_first_change(data.features) if SPLIT else None,\n",
    "    patience=20\n",
    "    #loss=\"triplet\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "261f71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de3eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame({key:val for key, val in train_trainer.logger.history.items() if len(val) > 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3bf23e",
   "metadata": {},
   "source": [
    "### Get first FP distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95fb1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    accelerator=\"gpu\"\n",
    ")\n",
    "scores = get_df_prediction(trainer, model=models, compared=data)\n",
    "#scores\n",
    "print(f\"ROC: {roc_auc_score(scores.IsAPair, scores.Probability)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1e6b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[~scores.IsAPair].sort_values(\"Distance\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2996d36",
   "metadata": {},
   "source": [
    "## Evaluating Dev for Test Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "064d4873",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    accelerator=\"gpu\"\n",
    ")\n",
    "dev_pairs = get_df_prediction(trainer, model=models, compared=data_dev)\n",
    "#scores\n",
    "print(f\"ROC: {roc_auc_score(dev_pairs.IsAPair, dev_pairs.Probability)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90f14030",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_pairs[~dev_pairs.IsAPair].sort_values(\"Distance\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c86d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_pairs.Distance.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83a93d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clip = scores.Distance.apply(lambda x: 2 if x > 2 else x)\n",
    "#scores.Distance = clip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0da00f",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Study AUCROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2706b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aucroc_curve(dev_pairs.IsAPair, dev_pairs[METRICKEY], nth=100, is_dist=ISDIST)\n",
    "ax = plt.gca()\n",
    "ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.gcf().savefig(make_file_name(\"aucroc-dev.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d09dc46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cls in dev_pairs.ComparedClass.unique():\n",
    "    plt.figure()\n",
    "    sns.boxplot(data=dev_pairs[(dev_pairs.ComparedClass==cls)], x=\"IsAPair\", y=METRICKEY)\n",
    "    plt.gca().set_title(cls)\n",
    "    plt.gcf().savefig(make_file_name(f\"Dev-{cls}.png\"))\n",
    "    #scores.groupby(\"ComparedClass\").plot.box(y=\"Distance\", x=\"IsAPair\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d201f876",
   "metadata": {},
   "source": [
    "### Find sweet spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a4cb91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DISTANCE = 6\n",
    "get_scores(dev_pairs, MAX_DISTANCE)\n",
    "print(\"\\n===\\nWithout sampling\\n===\\n\")\n",
    "get_scores(dev_pairs[(dev_pairs.ComparedLabel != dev_pairs.ComparatorLabel)], MAX_DISTANCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7627ab",
   "metadata": {},
   "source": [
    "## Evaluating Test with Dev Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e410002",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "MAX_DISTANCE = 6\n",
    "\n",
    "test_pairs = get_df_prediction(trainer, model=models, compared=data_test, threshold=MAX_DISTANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "298cd2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs[~test_pairs.IsAPair].sort_values(METRICKEY).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9f02bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC: {roc_auc_score(test_pairs.IsAPair, test_pairs.Probability)}\")\n",
    "MAX_DISTANCE = 6\n",
    "get_scores(test_pairs, MAX_DISTANCE)\n",
    "print(\"\\n===\\nWithout sampling\\n===\\n\")\n",
    "get_scores(test_pairs[(test_pairs.ComparedLabel != test_pairs.ComparatorLabel)], MAX_DISTANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4646b5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_aucroc_curve(test_pairs.IsAPair, test_pairs[METRICKEY], nth=75, is_dist=ISDIST)\n",
    "ax = plt.gca()\n",
    "ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.gcf().savefig(make_file_name(\"test-aucroc.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03cc9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_pairs.to_csv(make_file_name(\"test-results.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2992aa53",
   "metadata": {},
   "source": [
    "## On Voicu !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b6acbe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "df = pd.read_csv(\"pc-features.csv\")\n",
    "DFW = DataframeWrapper(df, label=(\"author\", \"title\"), target=\"title\", \n",
    "                       x_ignore=[col for col in df.columns if col not in data.features])\n",
    "#\n",
    "print(len(DFW.features))\n",
    "print(len(data.features))\n",
    "DFW.update_features(data.features)\n",
    "assign_normalization(DFW)\n",
    "#DFW._features = data.features\n",
    "print(len(data.features))\n",
    "print(len(DFW.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24b29037",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models.eval()\n",
    "pairs = get_df_prediction(\n",
    "    trainer, model=models, \n",
    "    compared=DFW, #comparator=DFW, \n",
    "    threshold=MAX_DISTANCE\n",
    ")\n",
    "pairs = pairs[pairs.ComparedLabel != pairs.ComparatorLabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "264bc447",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[\"ComparedClass\"] = pairs.ComparedLabel.apply(lambda x: x.split()[0].strip())\n",
    "pairs[\"ComparatorClass\"] = pairs.ComparatorLabel.apply(lambda x: x.split()[0].strip())\n",
    "pairs[\"IsAPair\"] = pairs.ComparedClass == pairs.ComparatorClass\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43fae1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[f\"Rounded{METRICKEY}\"] = pairs[METRICKEY].round(3)\n",
    "dists = sorted(pairs[f\"Rounded{METRICKEY}\"].unique())\n",
    "\n",
    "pairs[\"TestTPR\"] = .0\n",
    "pairs[\"TestPre\"] = .0\n",
    "pairs[\"TestFPR\"] = 1.0\n",
    "pairs[\"TestFP\"] = -1\n",
    "pairs[\"TestFN\"] = -1\n",
    "pairs[\"TestTP\"] = -1\n",
    "pairs[\"TestTN\"] = -1\n",
    "pairs[\"DevTPR\"] = .0\n",
    "pairs[\"DevPre\"] = .0\n",
    "pairs[\"DevFPR\"] = 1.0\n",
    "pairs[\"DevFP\"] = -1\n",
    "pairs[\"DevFN\"] = -1\n",
    "pairs[\"DevTP\"] = -1\n",
    "pairs[\"DevTN\"] = -1\n",
    "\n",
    "for dist in dists:\n",
    "    tp, fp, tn, fn = get_scores(test_pairs, dist, col=METRICKEY, noprint=True)\n",
    "    #print(tp, fp, tn, fn)\n",
    "    filt = pairs[f\"Rounded{METRICKEY}\"] == dist\n",
    "    pairs.loc[filt, \"TestTPR\"] = tp / max([tp+fn, 1])\n",
    "    pairs.loc[filt, \"TestFPR\"] = fp / max([fp+tn, 1])\n",
    "    pairs.loc[filt, \"TestPre\"] = tp / max([fp+tp, 1])\n",
    "    pairs.loc[filt, \"TestFP\"] = fp\n",
    "    pairs.loc[filt, \"TestTP\"] = tp\n",
    "    pairs.loc[filt, \"TestFN\"] = fn\n",
    "    pairs.loc[filt, \"TestTN\"] = tn\n",
    "    \n",
    "    # DEV\n",
    "    \n",
    "    tp, fp, tn, fn = get_scores(dev_pairs, dist, col=METRICKEY, noprint=True)\n",
    "    #print(tp, fp, tn, fn)\n",
    "    filt = pairs[f\"Rounded{METRICKEY}\"] == dist\n",
    "    pairs.loc[filt, \"DevTPR\"] = tp / max([tp+fn, 1])\n",
    "    pairs.loc[filt, \"DevFPR\"] = fp / max([fp+tn, 1])\n",
    "    pairs.loc[filt, \"DevPre\"] = tp / max([fp+tp, 1])\n",
    "    pairs.loc[filt, \"DevFP\"] = fp\n",
    "    pairs.loc[filt, \"DevTP\"] = tp\n",
    "    pairs.loc[filt, \"DevFN\"] = fn\n",
    "    pairs.loc[filt, \"DevTN\"] = tn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f88ec5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.sort_values(\"DevPre\").tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a563ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.sort_values([\"DevPre\", \"TestPre\", \"Distance\"]).to_csv(make_file_name(\"pairs-last-experiment.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4becec7f",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45149bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from freestyl.supervised.siamese.features.data import make_dataloader\n",
    "import torch\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    accelerator=\"gpu\"\n",
    ")\n",
    "\n",
    "# We first get the wonderful classes of compared\n",
    "dev_vectors, _ = zip(\n",
    "    *trainer.predict(models, make_dataloader(data_dev, model=models, batch_size=8))\n",
    ")\n",
    "dev_vectors = torch.cat([vec.cpu() for vec in dev_vectors], dim=0)\n",
    "dataframe = []\n",
    "for label, author, vector in zip(data_dev.get_labels(), data_dev.ys.tolist(), dev_vectors.tolist()):\n",
    "    dataframe.append((author, label.split(\" - \")[1], *vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c6a2a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first get the wonderful classes of compared\n",
    "test_vectors, _ = zip(\n",
    "    *trainer.predict(models, make_dataloader(data_test, model=models, batch_size=8))\n",
    ")\n",
    "test_vectors = torch.cat([vec.cpu() for vec in test_vectors], dim=0)\n",
    "dataframe = []\n",
    "for label, author, vector in zip(data_test.get_labels(), data_test.ys.tolist(), test_vectors.tolist()):\n",
    "    dataframe.append((author, label.split(\" - \")[1], *vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf5ff799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first get the wonderful classes of compared\n",
    "# pcs, _ = zip(\n",
    "#     *trainer.predict(models, make_dataloader(DFW, model=models, batch_size=8))\n",
    "# )\n",
    "# pcs = torch.cat([vec.cpu() for vec in pcs], dim=0)\n",
    "\n",
    "\n",
    "# for label, vector in zip(DFW.get_labels(), pcs.tolist()):\n",
    "#     author, label = label.split(\" - \")\n",
    "#     dataframe.append((author, label, *vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5383ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataframe, columns=[\"Author\", \"Title\", *[f\"Dim{i}\" for i in range(len(vector))]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e51ba8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "umap_2d = UMAP(n_components=2, init='random', random_state=0)\n",
    "\n",
    "proj_2d = umap_2d.fit_transform(df.loc[:, \"Dim0\":])\n",
    "\n",
    "fig_2d = px.scatter(\n",
    "    proj_2d, x=0, y=1,\n",
    "    color=df.Author,\n",
    "    labels={'color': 'Author'},\n",
    "    hover_name=df.Title,\n",
    "    #hover_data=[\"Author\", \"Title\"]\n",
    ")\n",
    "\n",
    "fig_2d.show()\n",
    "fig_2d.write_html(make_file_name(\"plotly.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3c52726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataframe, columns=[\"Author\", \"Title\", *[f\"Dim{i}\" for i in range(len(vector))]])\n",
    "df = df[df.Author.str.contains(\"PC\")]\n",
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "umap_2d = UMAP(n_components=2, init='random', random_state=0)\n",
    "\n",
    "proj_2d = umap_2d.fit_transform(df.loc[:, \"Dim0\":])\n",
    "\n",
    "fig_2d = px.scatter(\n",
    "    proj_2d, x=0, y=1,\n",
    "    color=df.Author,\n",
    "    labels={'color': 'Author'},\n",
    "    hover_name=df.Title,\n",
    "    #hover_data=[\"Author\", \"Title\"]\n",
    ")\n",
    "\n",
    "fig_2d.show()\n",
    "fig_2d.write_html(make_file_name(\"pc-plotly.html\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
