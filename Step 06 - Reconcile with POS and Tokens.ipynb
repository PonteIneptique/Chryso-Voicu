{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1e7620",
   "metadata": {},
   "source": [
    "This notebook builds together samples, and then retrieves statistics for each terms / POS. It also builds the sequence for POS-MFW text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76e8c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documenting\n",
    "from typing import Generator, List, Tuple\n",
    "\n",
    "# OS\n",
    "import glob\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "# Data\n",
    "import csv\n",
    "import json\n",
    "import lxml.etree as ET\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Operations\n",
    "import regex as re\n",
    "import unicodedata\n",
    "\n",
    "# UI\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ae65a",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a9fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_MFW = 1000\n",
    "NB_MFT = 1000\n",
    "NB_MFP = 100\n",
    "SAMPLE_SIZE = 1000\n",
    "MAX_NB_SAMPLE = 5\n",
    "MARGIN = SAMPLE_SIZE // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3bca6b",
   "metadata": {},
   "source": [
    "## Reading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8189a294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsv(file):\n",
    "    for line in file:\n",
    "        yield line.split()[:2]\n",
    "\n",
    "def normalize_tsv(file):\n",
    "    for tok, pos in read_tsv(file):\n",
    "        yield tok.lower(), pos[0]\n",
    "        \n",
    "def get_tokens(file):\n",
    "    with open(f\"./tagged/{file}-tagged.txt\") as f:\n",
    "        yield from normalize_tsv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb9a6a2",
   "metadata": {},
   "source": [
    "## Parsing MFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9124107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v-l-n',\n",
       " 'l-n-v',\n",
       " 'n-l-n',\n",
       " 'l-n-l',\n",
       " 'r-l-n',\n",
       " 'l-n-p',\n",
       " 'l-a-n',\n",
       " 'l-n-n',\n",
       " 'n-v-l',\n",
       " 'l-n-b']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_mfw(nb=500):\n",
    "    with open(\"./mfw.json\") as f:\n",
    "        d = json.load(f)\n",
    "    return [token for token, number in d if token != \"'\"][:nb]\n",
    "\n",
    "def load_mfp(nb=500):\n",
    "    with open(\"./mfp.json\") as f:\n",
    "        d = json.load(f)\n",
    "    return [token for token, number in d][:nb]\n",
    "\n",
    "MFW = load_mfw(NB_MFW)\n",
    "MFP = load_mfp(NB_MFP)\n",
    "MFP[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdce841",
   "metadata": {},
   "source": [
    "## Sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd2e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_TYPE = str\n",
    "POS_TYPE = str\n",
    "\n",
    "\n",
    "def is_punct(token: str, pos: str) -> bool:\n",
    "    return pos == \"u\" or token == \"'\"\n",
    "\n",
    "\n",
    "def extract_tokens(\n",
    "    inputs: List[Tuple[TOKEN_TYPE, POS_TYPE]],\n",
    "    sample_size: int\n",
    ") -> List[List[Tuple[TOKEN_TYPE, POS_TYPE]]]:\n",
    "    \n",
    "    sample = []\n",
    "    current_size = 0\n",
    "    \n",
    "    for token, pos in inputs:\n",
    "        if not is_punct(token, pos):\n",
    "            current_size += 1\n",
    "            \n",
    "        sample.append((token, pos))\n",
    "        \n",
    "        if current_size >= sample_size:\n",
    "            yield sample\n",
    "            current_size = 0\n",
    "            sample = []\n",
    "            \n",
    "def get_pos_text(\n",
    "    text: List[Tuple[TOKEN_TYPE, POS_TYPE]]\n",
    ") -> str:\n",
    "    return \" \".join([\n",
    "        tok if tok.lower() in MFW or is_punct(tok, pos) else pos\n",
    "        for tok, pos in text\n",
    "    ])\n",
    "\n",
    "def get_trigrams(tokens: List[str]) -> List[str]:\n",
    "    return [\"-\".join(tokens[i:i+3]) for i in range(len(tokens)-3+1)]\n",
    "\n",
    "def get_text(tokens):\n",
    "    return \" \".join([t for t, _ in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d484ffd",
   "metadata": {},
   "source": [
    "## Importing preparsed texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f198840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.read_csv(\"tlg-texts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f3074c",
   "metadata": {},
   "source": [
    "## Get the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a35f64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [00:26, 26.91it/s]\n"
     ]
    }
   ],
   "source": [
    "out_data = []\n",
    "\n",
    "for idx, text in tqdm.tqdm(texts.iterrows()):\n",
    "    poses = list(get_tokens(text.file))\n",
    "    size = len(poses)\n",
    "    local_margin = MARGIN\n",
    "    local_samples = 1 \n",
    "    # We count the number of potential samples ahead\n",
    "    potential_samples = (size - MARGIN*2) // SAMPLE_SIZE\n",
    "    \n",
    "    # If the size of the sample is below the margin + sample size\n",
    "    if (MARGIN*2+SAMPLE_SIZE) > size:\n",
    "        local_margin = (size - SAMPLE_SIZE) // 2\n",
    "    # Otherwise, check if we can extract multiple samples\n",
    "    elif potential_samples > 1: \n",
    "        local_samples = min(potential_samples, MAX_NB_SAMPLE)\n",
    "    \n",
    "    samples = list(extract_tokens(poses[local_margin:], SAMPLE_SIZE))\n",
    "    # We shuffle the sample order\n",
    "    random.shuffle(samples)\n",
    "    \n",
    "    for sample in samples[:local_samples]:\n",
    "        modified_text = get_pos_text(sample)\n",
    "        tokens, pos = zip(*[(tok, pos) for tok, pos in sample if not is_punct(tok, pos)])\n",
    "        filtered_tokens = Counter([tok for tok in tokens if tok in MFW])\n",
    "        filtered_tokens_count = sum(filtered_tokens.values())\n",
    "        pos = Counter([trig for trig in get_trigrams(pos) if trig in MFP])\n",
    "        pos_count = sum(pos.values())\n",
    "        out_data.append({\n",
    "            \"file\": text[\"file\"],\n",
    "            \"author\": text[\"author\"],\n",
    "            \"title\": text[\"title\"],\n",
    "            \"textgroup\": text[\"textgroup\"],\n",
    "            \"tokens\": get_text(sample),\n",
    "            \"length\": len(tokens),\n",
    "            \"modified_text\": modified_text,\n",
    "            **{\n",
    "                f\"$POS${pos}\": freq/pos_count\n",
    "                for pos, freq in pos.items()\n",
    "            },\n",
    "            **{\n",
    "                f\"$MFW${tok}\": freq/filtered_tokens_count\n",
    "                for tok, freq in filtered_tokens.items()\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01026d8",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb938f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2322, 1107)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(out_data)\n",
    "df.to_csv(\"tlg-features.csv\", index=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b7fac2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adamantius\n",
      "Alexander\n",
      "Amphilochius\n",
      "Antonius Hagiographus\n",
      "Asterius\n",
      "Asterius Sophista\n",
      "Athanasius\n",
      "Barlaam,\n",
      "Basilius\n",
      "Clemens Alexandrinus\n",
      "Clemens Romanus Clementina\n",
      "Cyrillus\n",
      "Didymus Caecus Didymus the Blind\n",
      "Dio Chrysostomus\n",
      "Ephraem\n",
      "Ephraem Syrus\n",
      "Epiphanius\n",
      "Eusebius\n",
      "Eustathius\n",
      "Evagrius\n",
      "Flavius Justinianus Imperator\n",
      "Gregorius Nazianzenus\n",
      "Gregorius Nyssenus\n",
      "Gregorius Thaumaturgus\n",
      "Hesychius\n",
      "Hippolytus\n",
      "Irenaeus\n",
      "Joannes\n",
      "Joannes Chrysostomus John Chrysostom\n",
      "Joannes Damascenus John of Damascus\n",
      "Julianus\n",
      "Leontius\n",
      "Marcellus\n",
      "Marcus Diaconus\n",
      "Maximus Confessor\n",
      "Nemesius\n",
      "Nicephorus I,\n",
      "Nicetas Choniates,\n",
      "Nicolaus I Mysticus\n",
      "Olympiodorus Diaconus\n",
      "Origenes\n",
      "Palladius\n",
      "Petrus\n",
      "Procopius\n",
      "Salaminius Hermias Sozomenus\n",
      "Severianus\n",
      "Theodoretus\n",
      "Theodorus Studites\n"
     ]
    }
   ],
   "source": [
    "for x in sorted(df.author.unique()):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcba7d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [00:01, 52.69it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = pd.read_csv(\"pc-texts.csv\")\n",
    "\n",
    "pc_data = []\n",
    "\n",
    "for idx, text in tqdm.tqdm(texts.iterrows()):\n",
    "    poses = list(get_tokens(text.file))\n",
    "    size = len(poses)\n",
    "    local_margin = MARGIN\n",
    "    local_samples = 1 \n",
    "    # We count the number of potential samples ahead\n",
    "    potential_samples = (size - MARGIN*2) // SAMPLE_SIZE\n",
    "    \n",
    "    # If the size of the sample is below the margin + sample size\n",
    "    if (MARGIN*2+SAMPLE_SIZE) > size:\n",
    "        local_margin = (size - SAMPLE_SIZE) // 2\n",
    "    # Otherwise, check if we can extract multiple samples\n",
    "    elif potential_samples > 1: \n",
    "        local_samples = min(potential_samples, MAX_NB_SAMPLE)\n",
    "    \n",
    "    # Right version :\n",
    "    #samples = list(extract_tokens(poses[local_margin:], SAMPLE_SIZE))\n",
    "    samples = [poses]\n",
    "    #print(samples)\n",
    "    \n",
    "    #samples = []\n",
    "    # We shuffle the sample order\n",
    "    random.shuffle(samples)\n",
    "    \n",
    "    for sample in samples[:local_samples]:\n",
    "        modified_text = get_pos_text(sample)\n",
    "        tokens, pos = zip(*[(tok, pos) for tok, pos in sample if not is_punct(tok, pos)])\n",
    "        filtered_tokens = Counter([tok for tok in tokens if tok in MFW])\n",
    "        filtered_tokens_count = sum(filtered_tokens.values())\n",
    "        pos = Counter([trig for trig in get_trigrams(pos) if trig in MFP])\n",
    "        pos_count = sum(pos.values())\n",
    "        pc_data.append({\n",
    "            \"file\": text[\"file\"],\n",
    "            \"author\": text[\"author\"],\n",
    "            \"title\": text[\"title\"],\n",
    "            #\"textgroup\": text[\"textgroup\"],\n",
    "            \"tokens\": get_text(sample),\n",
    "            \"length\": len(tokens),\n",
    "            \"modified_text\": modified_text,\n",
    "            **{\n",
    "                f\"$POS${pos}\": freq/pos_count\n",
    "                for pos, freq in pos.items()\n",
    "            },\n",
    "            **{\n",
    "                f\"$MFW${tok}\": freq/filtered_tokens_count\n",
    "                for tok, freq in filtered_tokens.items()\n",
    "            }\n",
    "        })\n",
    "        \n",
    "df = pd.DataFrame(pc_data)\n",
    "df.to_csv(\"pc-features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
