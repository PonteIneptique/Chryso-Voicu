{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7162a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thibault/dev/chrysostylom/env/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/thibault/dev/chrysostylom/env/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator12recordStreamERKNS_7DataPtrENS0_10CUDAStreamE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/home/thibault/dev/chrysostylom/env/lib/python3.10/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/home/thibault/dev/chrysostylom/env/lib/python3.10/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from freestyl.dataset.dataframe_wrapper import DataframeWrapper\n",
    "from freestyl.supervised.siamese import train_dataframewrappers\n",
    "from freestyl.supervised.siamese import get_df_prediction\n",
    "from freestyl.supervised.siamese.utils import score_from_preds\n",
    "from freestyl.utils import plot_aucroc_curve\n",
    "#>>> x = [1, 2, 3, 4, 5, 6]\n",
    "#>>> .shuffle(x)\n",
    "\n",
    "NEW_DATASET = False\n",
    "\n",
    "seed = 42\n",
    "IGNORE_KEYS = [\n",
    "    \"file\", \"author\", \"textgroup\", \"title\", \"tokens\", \"length\", \"modified_text\"\n",
    "]\n",
    "REMOVED = [\"Euclides\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a05a14",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48da1ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape : (1867, 1107)\n",
      "Dev Shape : (207, 1107)\n",
      "Test Shape : (248, 1107)\n"
     ]
    }
   ],
   "source": [
    "def get_train_dev_test(filtre, seed=42, ratio=10):\n",
    "    test = len(filtre) * ratio // 100\n",
    "    dev_and_test = test * 2\n",
    "    print(f\"Train categorical samples: {len(filtre)-dev_and_test}\")\n",
    "    print(f\"Dev   categorical samples: {dev_and_test-test}\")\n",
    "    print(f\"Test  categorical samples: {test}\")\n",
    "    #r = random.Random(seed)\n",
    "    #r.shuffle(filtre)\n",
    "    return filtre[:-dev_and_test], filtre[-dev_and_test:-test], filtre[-test:]\n",
    "\n",
    "\n",
    "if NEW_DATASET:\n",
    "    df = pd.read_csv(\"tlg-features.csv\").sample(frac=1)\n",
    "    #df = df[df.tokens >= 5000]\n",
    "    #print(\">= 5000\", df.shape)\n",
    "    #df = df[~df.file.isin(POETRY)]\n",
    "    #print(\">= Poetry\", df.shape)\n",
    "    # df = df[~df.title.str.contains(\"Dub\\.|Sp\\.|Fragm|Excerpt|(e cod\\.)|Suda|recensio|fragm|sp\\.|dub\\.|(fort\\. auctore)|Scholia\")]\n",
    "    print(\"Title filter\", df.shape)\n",
    "    #df = df[~df[\"full-pos-text\"].isna()]\n",
    "    #print(\">= POS missing\", df.shape)\n",
    "    \n",
    "    # Filter based on authors, to generalize better. Everything should be out of domain\\\n",
    "    train, dev, test = [], [], []\n",
    "    if SPLIT_ON_AUTHORS:\n",
    "        authors = df.author.value_counts()\n",
    "        a, b, c = get_train_dev_test(authors[authors > 1].index.tolist())\n",
    "    else:\n",
    "        a, b, c = get_train_dev_test(df.index.tolist())\n",
    "        \n",
    "    train.extend(a)\n",
    "    dev.extend(b)\n",
    "    test.extend(c)\n",
    "    \n",
    "#     a, b, c = get_train_dev_test(authors[authors == 1].index.tolist())\n",
    "#     train.extend(a)\n",
    "#     dev.extend(b)\n",
    "#     test.extend(c)\n",
    "\n",
    "    if SPLIT_ON_AUTHORS:\n",
    "        train = df[df.author.isin(train)].copy(deep=True)\n",
    "        dev = df[df.author.isin(dev)].copy(deep=True)#.author.value_counts()\n",
    "        test = df[df.author.isin(test)].copy(deep=True)#.author.value_counts()\n",
    "    else:\n",
    "        train = df[df.index.isin(train)].copy(deep=True)\n",
    "        dev = df[df.index.isin(dev)].copy(deep=True)#.author.value_counts()\n",
    "        test = df[df.index.isin(test)].copy(deep=True)#.author.value_counts()\n",
    "        \n",
    "    train.to_csv(\"tlg-train.csv\", index=False)\n",
    "    dev.to_csv(\"tlg-dev.csv\", index=False)\n",
    "    test.to_csv(\"tlg-test.csv\", index=False)\n",
    "else:\n",
    "    train = pd.read_csv(\"tlg-train.csv\")\n",
    "    dev = pd.read_csv(\"tlg-dev.csv\")\n",
    "    test = pd.read_csv(\"tlg-test.csv\")\n",
    "    \n",
    "train = train[~train.author.isin(REMOVED)]\n",
    "dev = dev[~dev.author.isin(REMOVED)]\n",
    "test = test[~test.author.isin(REMOVED)]\n",
    "\n",
    "print(f\"Train Shape : {train.shape}\")\n",
    "print(f\"Dev Shape : {dev.shape}\")\n",
    "print(f\"Test Shape : {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f1fe97",
   "metadata": {},
   "source": [
    "## Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93104837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_normalization(dfw):\n",
    "    dfw.normalized._dataframe = dfw.dataframe.fillna(0)\n",
    "    \n",
    "def get_scores(scores, distance: float) -> None:\n",
    "    scores[\"Attribution\"] = scores.Distance < distance\n",
    "    tp = scores[scores.IsAPair].Attribution.sum() \n",
    "    fn = scores[scores.IsAPair].Attribution.shape[0] - tp\n",
    "    fp = scores[~scores.IsAPair].Attribution.sum()\n",
    "    print(f\"True positives: {tp}\\nFalse Negative {fn}\")\n",
    "    print(f\"False positives: {fp}\\nAccuracy: {tp/(fn+tp):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c933d1b0",
   "metadata": {},
   "source": [
    "## Automatically retrieve some constant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03479c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_COLS = [\n",
    "    col\n",
    "    for col in train.columns\n",
    "    if col.startswith(\"$POS$\")\n",
    "]\n",
    "FW_COLS = [\n",
    "    col\n",
    "    for col in train.columns\n",
    "    if col.startswith(\"$MFW$\")\n",
    "]\n",
    "IGNORE = set(IGNORE_KEYS + POS_COLS + FW_COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d218e4",
   "metadata": {},
   "source": [
    "## Get DataFrameWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa538a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataframeWrapper(train, target=\"author\", label=[\"author\", \"title\"], x_ignore=IGNORE)\n",
    "assign_normalization(data)\n",
    "data_dev = DataframeWrapper(dev, target=\"author\", label=[\"author\", \"title\"], x_ignore=IGNORE)\n",
    "assign_normalization(data_dev)\n",
    "data_test = DataframeWrapper(test, target=\"author\", label=[\"author\", \"title\"], x_ignore=IGNORE)\n",
    "assign_normalization(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f31594",
   "metadata": {},
   "source": [
    "## CHecking some details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d3f69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.xs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307d8cf",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e62a60c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SiameseSequentialModule.__init__() got an unexpected keyword argument 'miner_for_dev'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m models, trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataframewrappers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dev\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmargin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequential\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlinearManhattan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequential_min_token_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocument_hidden_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminer_for_dev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequential_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAttentionalGRU\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequential_text_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodified_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Chryso-Voicu/freestyl/supervised/siamese/utils.py:103\u001b[0m, in \u001b[0;36mtrain_dataframewrappers\u001b[0;34m(train, dev, test, accelerator, sample, batch_size, min_delta, patience, sequential_text_key, callbacks, gpus, max_epochs, min_epochs, sequential_min_token_freq, mode, **hyperparams)\u001b[0m\n\u001b[1;32m     98\u001b[0m     doc_encoder \u001b[38;5;241m=\u001b[39m DocumentEncoder(\n\u001b[1;32m     99\u001b[0m         bilevel\u001b[38;5;241m=\u001b[39m(hyperparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequential_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, SiameseSequentialModule\u001b[38;5;241m.\u001b[39mDEFAULT) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttentionalGRU\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m     doc_encoder\u001b[38;5;241m.\u001b[39mfrom_series(train\u001b[38;5;241m.\u001b[39mdataframe[sequential_text_key], min_frequency\u001b[38;5;241m=\u001b[39msequential_min_token_freq)\n\u001b[0;32m--> 103\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSiameseSequentialModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocument_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhyperparams\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     make_dataloader \u001b[38;5;241m=\u001b[39m FeatureDataLoader\n",
      "\u001b[0;31mTypeError\u001b[0m: SiameseSequentialModule.__init__() got an unexpected keyword argument 'miner_for_dev'"
     ]
    }
   ],
   "source": [
    "models, trainer = train_dataframewrappers(\n",
    "    train=data,\n",
    "    dev=data_dev,\n",
    "    test=data_test,\n",
    "    learning_rate=1e-3,\n",
    "    margin=1,\n",
    "    mode=\"sequential\",\n",
    "    loss=\"linearManhattan\",\n",
    "    sample=None,\n",
    "    batch_size=128,\n",
    "    gpus=1,\n",
    "    accelerator=\"gpu\",\n",
    "    min_epochs=100,\n",
    "    patience=10,\n",
    "    sequential_min_token_freq=5,\n",
    "    document_hidden_size = 128,\n",
    "    embedding_size = 100,\n",
    "    dropout=.30,\n",
    "    miner_for_dev=True,\n",
    "    sequential_model=\"AttentionalGRU\",\n",
    "    sequential_text_key=\"modified_text\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2311e601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SiameseSequentialModule(\n",
       "   (aucroc): AUROC()\n",
       "   (distance): LpDistance()\n",
       "   (linear): Sequential(\n",
       "     (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "   )\n",
       "   (_subloss): BCEWithLogitsLoss()\n",
       "   (_linear_miner): BatchEasyHardMiner(\n",
       "     (distance): LpDistance()\n",
       "   )\n",
       "   (miner): BatchEasyHardMiner(\n",
       "     (distance): LpDistance()\n",
       "   )\n",
       "   (document_encoder): DocumentEncoder(\n",
       "     (_vocab): Vocab()\n",
       "   )\n",
       "   (net): TextGRU(\n",
       "     (embed): Embedding(1059, 10, padding_idx=1)\n",
       "     (gru): GRU(10, 32, batch_first=True, bidirectional=True)\n",
       "     (dropout): Dropout(p=0.15, inplace=False)\n",
       "   )\n",
       " ),\n",
       " <pytorch_lightning.trainer.trainer.Trainer at 0x7fbdfec3ab30>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2996d36",
   "metadata": {},
   "source": [
    "## Evaluating Dev for Test Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064d4873",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thibault/dev/chrysostylom/env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'hparams'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      2\u001b[0m     gpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      3\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mget_df_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#scores\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc_score(scores\u001b[38;5;241m.\u001b[39mIsAPair, scores\u001b[38;5;241m.\u001b[39mProbability)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/Chryso-Voicu/freestyl/supervised/siamese/utils.py:283\u001b[0m, in \u001b[0;36mget_df_prediction\u001b[0;34m(trainer, model, compared, comparator, threshold, k)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_df_prediction\u001b[39m(\n\u001b[1;32m    273\u001b[0m     trainer: pl\u001b[38;5;241m.\u001b[39mTrainer,\n\u001b[1;32m    274\u001b[0m     model: BaseSiameseModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m     k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PairsDataframe:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;124;03m\"\"\" Gets predictions for a df using another df as comparison\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     label_encoder: LabelEncoder \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241m.\u001b[39mlabel_encoder\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, SiameseFeatureModule):\n\u001b[1;32m    286\u001b[0m         make_dataloader \u001b[38;5;241m=\u001b[39m FeatureDataLoader\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'hparams'"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    accelerator=\"gpu\"\n",
    ")\n",
    "\n",
    "scores = get_df_prediction(trainer, model=models, compared=data_dev)\n",
    "#scores\n",
    "print(f\"ROC: {roc_auc_score(scores.IsAPair, scores.Probability)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[scores.Distance < 1].Distance.plot.box()\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0da00f",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Study classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09dc46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cls in scores.ComparedClass.unique():\n",
    "    plt.figure()\n",
    "    sns.boxplot(data=scores[(scores.ComparedClass==cls) & (scores.Distance<1)], x=\"IsAPair\", y=\"Distance\")\n",
    "    plt.gca().set_title(cls)\n",
    "    #scores.groupby(\"ComparedClass\").plot.box(y=\"Distance\", x=\"IsAPair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1325bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_PROBA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4cb91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DISTANCE = .75\n",
    "get_scores(scores, MAX_DISTANCE)\n",
    "print(\"\\n===\\nWithout sampling\\n===\\n\")\n",
    "get_scores(scores[(scores.ComparedLabel != scores.ComparatorLabel)], MAX_DISTANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2706b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aucroc_curve(scores.IsAPair, scores.Probability, nth=1000)\n",
    "ax = plt.gca()\n",
    "ax.legend(bbox_to_anchor=(1.1, 1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7627ab",
   "metadata": {},
   "source": [
    "## Evaluating Test with Dev Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e410002",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "MAX_DISTANCE = .75\n",
    "\n",
    "pairs = get_df_prediction(trainer, model=models, compared=data_test, threshold=MAX_DISTANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f02bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC: {roc_auc_score(pairs.IsAPair, pairs.Probability)}\")\n",
    "MAX_DISTANCE = .75\n",
    "get_scores(scores, MAX_DISTANCE)\n",
    "print(\"\\n===\\nWithout sampling\\n===\\n\")\n",
    "get_scores(scores[(scores.ComparedLabel != scores.ComparatorLabel)], MAX_DISTANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4646b5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_aucroc_curve(pairs.IsAPair, pairs.Probability, nth=1000)\n",
    "ax = plt.gca()\n",
    "ax.legend(bbox_to_anchor=(1.1, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.to_csv(\"test-results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2992aa53",
   "metadata": {},
   "source": [
    "## On Voicu !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6acbe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "df = pd.read_csv(\"pc-features.csv\")\n",
    "DFW = DataframeWrapper(df, label=(\"author\", \"title\"), target=\"title\", \n",
    "                       x_ignore=IGNORE.union({'$MFW$Î¼Î·Î´', '$MFW$Îµá½–', '$MFW$á¼Ï‚', '$MFW$Ï„Î±á½Ï„á½¸Î½', '$MFW$á¼§Ï„Ï„Î¿Î½', '$MFW$Î¼Î¬Î»Î±', '$MFW$Î¿á½”Ï„', '$MFW$Ï„', '$MFW$Î³', '$MFW$á¼¤Ï„Î¿Î¹', '$MFW$á¼¥', '$MFW$Îµá¼´Ï€ÎµÏ', '$MFW$Î·', '$MFW$Îº', '$MFW$Î±', '$MFW$Î²', '$MFW$Î±Ê¹', '$MFW$[', '$MFW$p', '$MFW$Ì£', '$MFW$ð…»'}))\n",
    "#\n",
    "print(len(DFW.features))\n",
    "DFW.update_features(data.features)\n",
    "assign_normalization(DFW)\n",
    "#DFW._features = data.features\n",
    "print(len(data.features))\n",
    "print(len(DFW.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b29037",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "pairs = get_df_prediction(trainer, model=models, compared=DFW, threshold=1)\n",
    "pairs = pairs[pairs.ComparedLabel != pairs.ComparatorLabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264bc447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairs.to_csv(\"pairs-last-experiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b687f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.Attribution = pairs.Distance < .85\n",
    "print(f\"Pairing: {pairs.Attribution.sum()/len(pairs)}\")\n",
    "pairs[pairs.Distance < .85]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4594b103",
   "metadata": {},
   "source": [
    "## Add FP and TP for each distance based on test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
